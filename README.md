# Задачи машинного обучения
Собрание учебных и исследовательских задач по машинному обучению.
## Содержание
- [Задачи машинного обучения](#задачи-машинного-обучения)
  - [Содержание](#содержание)
  - [Обзор](#обзор)
  - [Классификация гистологических изображений легких](#классификация-гистологических-изображений-легких)
  - [Прогнозирование временных рядов на примере данных акций AMD](#прогнозирование-временных-рядов-на-примере-данных-акций-amd)
  - [Классификация плодов по их типу и свежести](#классификация-плодов-по-их-типу-и-свежести)
  - [Классификация сообщений по ментальному здоровью](#классификация-сообщений-по-ментальному-здоровью)

## Обзор
> В этом репозитории собраны задачи по машинному обучению:  
> - **Классификация**: задачи классификации текста и изображений.  
> - **Регрессия**: предсказание числовых величин. 

## Классификация гистологических изображений легких
**Постановка задачи:** Разработать модель глубокого обучения для классификации гистологических изображений легких на три класса:
- lung_aca (аденокарцинома),
- lung_n (нормальная ткань),
- lung_scc (плоскоклеточный рак).

**Исходные данные:**
- Датасет содержит 12,000 тренировочных и 3,000 тестовых изображений, распределенных по трем классам.
  
**Элементы решения:**
- Изображения предварительно обработаны: применены аугментации (рандомизированное изменение размера, нормализация) и разделены на подвыборки
- Использование предобученных архитектур из `torchvision.models`
- Замена последнего слоя для соответствия количеству классов (3)
- Реализация цикла обучения с расчетом потерь (CrossEntropyLoss)
  
**Результаты:**
  Модель на основе ResNet-50 показала высокую точность (92.4%) и надежность, что подтверждает ее предположительную применимость для автоматизации диагностики рака легких.

## Прогнозирование временных рядов на примере данных акций AMD
**Постановка задачи:** Разработать модель для прогнозирования временных рядов на примере данных акций AMD.

**Исходные данные:**
- Датасет с историческими данными акций
  
**Элементы решения:**
- Удаляются ненужные столбцы (Adj Close, Volume), нормализуются значения цен (Open, High, Low, Close).
- Формируются последовательности длиной 10 временных шагов для обучения моделей.
- Реализованы четыре архитектуры нейронных сетей: SimpleRNN (простая RNN) LSTMModel (LSTM), GRUModel (GRU), DeepLSTMModel (глубокая LSTM с BatchNorm и Dropout).
  
**Результаты:**
  Метрики обучения (тестовые потери после 20 эпох):
- SimpleRNN: ~0.000221

- LSTM: ~0.000360

- GRU: ~0.000202

DeepLSTM: ~0.001232
  GRU показала наименьшие потери, что делает её предпочтительной для данного набора данных.

## Классификация плодов по их типу и свежести
**Постановка задачи:** Классифицировать плоды с использованием глубокого обучения
**Исходные данные:**
- Папки Train и Test, где расположены фото различных плодов (испорченные и свежие)
  
**Элементы решения:**
- Балансировка путем ограничения количества образцов каждого класса до 1978.
- Случайные преобразования для тренировочных данных, такие как RandomHorizontalFlip, GaussianBlur и RandomAdjustSharpness.
- Модель SimpleCNN имеет три сверточных слоя и две полносвязные головы для того, чтобы классифицировать по двум признакам: тип плода и его свежесть.
  
**Результаты:**
    Модель достигла высокой точности (97%) в классификации фруктов, но хуже справляется с определением свежести (87.9%).

## Классификация сообщений по ментальному здоровью
**Постановка задачи:** Разработка модели для бинарной классификации текстовых данных (метки 0 и 1) на основе датасета, содержащего 27,977 текстовых примеров.
**Исходные данные:**
- Датасет с сообщениями и метками класса
  
**Элементы решения:**
- Проверка баланса классов (14,139 для класса 0 и 13,838 для класса 1).
- Использование TF-IDF для преобразования текста в числовые признаки.
- Методы: MultinomialNB, RandomForestClassifier, модель на основе TensorFlow с использованием слоев Embedding, LSTM, Dropout.
- Кросс-валидация для проверки устойчивости моделей.
  
**Результаты:**
- Наивный Байес и Случайный лес показали точность ~80-85%.
- Нейронная сеть достигла более высокой точности (~88-90%) благодаря учету контекста через LSTM.
- Матрица ошибок подтвердила сбалансированность ошибок между классами.
- Нейросетевой подход превзошел традиционные методы за счет учета последовательностей в тексте.